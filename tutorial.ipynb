{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-circular",
   "metadata": {},
   "source": [
    "# Object Detection by using Tensorflow and OpenCv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-terrorism",
   "metadata": {},
   "source": [
    "***\n",
    "**Introduction**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-religion",
   "metadata": {},
   "source": [
    "This notebook takes you step by step to create object detection model by using Tensorflow Object Detection API's <br><br>\n",
    "\n",
    "**Enviroment Specifications**:<br>\n",
    "- Windows 10 Enterpise\n",
    "- python version(3.8.8)\n",
    "- TensorFlow version(2.4.1) (Facing issues with 2.4.2)\n",
    "- numpy version version 1.19.5<br><br>\n",
    "\n",
    "\n",
    "**prerequisites** \n",
    "- Installing Tensorflow object Detections API's you can refer to below link [Installation Guide](http://https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html)<br>\n",
    "Note: As part of this installation many other depdencies need to be installed as well, please make sure to go through all installation steps, theyare bit long and may you would face some challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-probe",
   "metadata": {},
   "source": [
    "***\n",
    "**Imports**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-algebra",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Defining the Requiered Paths and Directories**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interpreted-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPT_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = 'Tensorflow/workspace/annotations'\n",
    "IMAGE_PATH = 'Tensorflow/workspace/images'\n",
    "MODEL_PATH = 'Tensorflow/workspace/models'\n",
    "PRETRAINED_MODEL_PATH = 'Tensorflow/workspace/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH + '/my_sdd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH + '/my_sdd_mobnet//'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-lemon",
   "metadata": {},
   "source": [
    "***\n",
    "**Label Mapp**\n",
    "***\n",
    "Before running the below code you need to open the label the image by running the labelImag.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "higher-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'can', 'id':1},{'name':'glass', 'id':2},{'name':'plastic', 'id':3}]\n",
    "\n",
    "with open(ANNOTATION_PATH + '/label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item{ \\n')\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-reconstruction",
   "metadata": {},
   "source": [
    "***\n",
    "**Creating Tfrecord files**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: RealTimeObjectDetection/Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: RealTimeObjectDetection/Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "!python {SCRIPT_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-bubble",
   "metadata": {},
   "source": [
    "***\n",
    "**Creating model directory and copy the pipeline config file to the model directory**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solar-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file RealTimeObjectDetection\\Tensorflow\\workspace\\models\\my_sdd_mobnet already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_sdd_mobnet'\n",
    "!mkdir {'RealTimeObjectDetection\\Tensorflow\\workspace\\models\\\\' + CUSTOM_MODEL_NAME}\n",
    "!copy RealTimeObjectDetection\\Tensorflow\\workspace\\pre-trained-models\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config RealTimeObjectDetection\\Tensorflow\\workspace\\models\\my_sdd_mobnet\\pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-enforcement",
   "metadata": {},
   "source": [
    "***\n",
    "**Configure the pipeline file**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proper-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(CONFIG_PATH, 'r') as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str,pipeline_config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stuffed-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 3\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "divided-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-making",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Running training from notebook**\n",
    "\n",
    "***\n",
    "Note: you need to replace the path of model_main_tf2.py with your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python C:\\Users\\Windows10-Desktop\\Tensorflow\\models\\research\\object_detection/model_main_tf2.py --model_dir=RealTimeObjectDetection/Tensorflow/workspace/models/my_sdd_mobnet --pipeline_config_path=C:\\Users\\Windows10-Desktop\\RealTimeObjectDetection\\Tensorflow\\workspace\\models\\my_sdd_mobnet\\pipeline.config --num_train_steps=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-classic",
   "metadata": {},
   "source": [
    "***\n",
    "**Running training from Anaconda Prompt**\n",
    "\n",
    "***\n",
    "Note: you need to replace the path of model_main_tf2.py with your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python C:\\Users\\Windows10-Desktop\\Tensorflow\\models\\research\\object_detection/model_main_tf2.py --model_dir=RealTimeObjectDetection/Tensorflow/workspace/models/my_sdd_mobnet --pipeline_config_path=C:\\Users\\Windows10-Desktop\\RealTimeObjectDetection\\Tensorflow\\workspace\\models\\my_sdd_mobnet\\pipeline.config --num_train_steps=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-museum",
   "metadata": {},
   "source": [
    "***\n",
    "**Inference**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technical-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1f89f1ac9a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-8')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "single-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "turned-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "metric-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('test24.mp4',fourcc, 20.0, (width,height),isColor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.7,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (1000, 600)))\n",
    "    out.write(image_np_with_detections)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-floating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
